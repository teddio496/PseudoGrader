from fastapi import APIRouter, HTTPException
from app.api.v1.models import PromptRequest, PromptResponse, GeminiErrorResponse
from app.core.config import settings, GEMINI_MODEL
from app.core.logging import setup_logger
import google.generativeai as genai
import asyncio

router = APIRouter()
logger = setup_logger("gemini")

@router.post("/generate", response_model=PromptResponse, responses={
    500: {"model": GeminiErrorResponse}
})
async def generate_response(request: PromptRequest) -> PromptResponse:
    """
    Generate Python code and pytest test cases from pseudocode using Google's Gemini model.

    The endpoint accepts pseudocode as input and returns both the Python implementation
    and corresponding pytest test cases.

    Args:
        request (PromptRequest): Request body containing:
            - prompt (str): The pseudocode to convert
            - max_retries (int, optional): Maximum number of retries for JSON parsing (1-5, default: 3)

    Returns:
        PromptResponse: Response containing:
            - code (str): The generated Python implementation
            - testing_code (str): The generated pytest test cases
            - model_used (str): The Gemini model version used

    Raises:
        HTTPException (500): 
            - When no response is generated by the model
            - When the model response is not valid JSON after max_retries attempts
            - For any other unexpected errors
    """
    max_retries = request.max_retries
    retry_count = 0

    while retry_count < max_retries:
        try:
            # Ensure API is configured
            genai.configure(api_key=settings.GOOGLE_API_KEY, transport="rest")
            
            # Use preset generation config
            generation_config = {
                "temperature": 0.0,     
                "top_p": 1.0,       
                "top_k": 0,     
                "candidate_count": 1,
                "max_output_tokens": 1000
            }
            
            # Prepare the code generation prompt
            code_prompt = f"""
            Convert the following pseudocode into Python code EXACTLY as specified. 
            Do not fix, re-arrange, or optimize anything. 
            If the pseudocode is contradictory or syntactically incorrect, replicate that as closely as possible in Python. 
            The goal is a near-verbatim translation from pseudocode into Python. 
            If any step in the pseudocode is ambiguous, maintain the same structure and variable usage. 
            Do not add error handling or assume missing details. 
            IMPORTANT: Return ONLY the raw Python code with ABSOLUTELY NO COMMENTS, NO DOCSTRINGS, and NO EXPLANATIONS. 
            The response should contain nothing but the actual code.

            Question Description:
            {request.description}

            Pseudocode:
            {request.prompt}
            """
            
            # Create a prompt for test generation that works with just the pseudocode
            # This allows us to start generating tests concurrently while code is being generated
            test_prompt = f"""
            Create pytest test cases for Python code that will be translated from this pseudocode:
            
            Question Description:
            {request.description}

            Pseudocode:
            {request.prompt}
            
            From analyzing the pseudocode above, create comprehensive pytest test cases to validate the Python implementation.
            Focus on testing functionality, edge cases, and expected behavior of the algorithm described in the pseudocode.
            Return ONLY the pytest test cases, no explanations or additional text.
            IMPORTANT: Do NOT include the original Python code in the test cases.
            """
            
            # Start both API calls concurrently
            # Create async functions to wrap the synchronous generate_content calls
            async def generate_code():
                return GEMINI_MODEL.generate_content(
                    contents=[{"text": code_prompt}],
                    generation_config=generation_config
                )
                
            async def generate_tests():
                return GEMINI_MODEL.generate_content(
                    contents=[{"text": test_prompt}],
                    generation_config=generation_config
                )
                
            # Run both tasks concurrently
            code_response, test_response = await asyncio.gather(
                generate_code(),
                generate_tests()
            )
            
            # Process code response
            if not code_response.text:
                raise HTTPException(status_code=500, detail="No code generated")
            
            python_code = code_response.text.strip()
            python_code = python_code.replace("```python", "").replace("```", "").strip()
            
            # Process test response
            if not test_response.text:
                raise HTTPException(status_code=500, detail="No test cases generated")
            
            testing_code = test_response.text.strip()
            testing_code = testing_code.replace("```python", "").replace("```", "").strip()
            
            # Return the combined response
            return PromptResponse(
                code=python_code,
                testing_code=testing_code,
            )
        
        except Exception as e:
            logger.error(f"Error in generate_response: {str(e)}")
            raise HTTPException(
                status_code=500,
                detail=GeminiErrorResponse(
                    error="Unexpected error in generate_response",
                    details=str(e),
                    retries_attempted=retry_count
                ).model_dump()
            )